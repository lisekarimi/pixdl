{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f7be44-b8e9-493e-96d6-b60d6987da1f",
   "metadata": {},
   "source": [
    "# üìù Handwritten Digits Classification\n",
    "---\n",
    "- üî¢ **Task:** Classifying handwritten digits (0-9) from images.\n",
    "- üß† **Model:** Convolutional Neural Network (CNN) with Data Augmentation.\n",
    "- üìà **Evaluation:** Accuracy, Loss, Confusion Matrix.  \n",
    "- üöÄ **Tools:** TensorFlow/Keras.  \n",
    "- üßë‚Äçüíª **Skill Level:** Intermediate Data Scientist.  \n",
    "- üéØ **Goal:** Develop an accurate and robust model that can recognize handwritten digits efficiently.\n",
    "\n",
    "- Requirements\n",
    "\n",
    "    * **Docker**: NVIDIA TensorFlow container (`nvcr.io/nvidia/tensorflow:25.06-tf2-py3`) and TensorFlow wheels for NVIDIA 50-series GPUs:\n",
    "      [https://github.com/nhsmit/tensorflow-rtx-50-series/releases/tag/2.20.0dev](https://github.com/nhsmit/tensorflow-rtx-50-series/releases/tag/2.20.0dev)\n",
    "    * **Hardware**: GPU\n",
    "    * **Tools**: Docker, WSL2 (Windows)\n",
    "\n",
    "- Quick Start\n",
    "\n",
    "    ```bash\n",
    "    make dev-tf  # Builds and runs the TensorFlow container; exposes JupyterLab on http://localhost:8888\n",
    "    ```\n",
    "    \n",
    "To add more libraries, update `Dockerfile.tf`:\n",
    "\n",
    "```dockerfile\n",
    "RUN python3.11 -m pip install --break-system-packages \\\n",
    "    pillow numpy matplotlib opencv-python pandas seaborn scikit-learn \\\n",
    "    jupyter jupyterlab ipywidgets tqdm\n",
    "```\n",
    "\n",
    "Let‚Äôs jump into it and start building our models! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07081fd-b6f5-46bc-a321-4757b74b747b",
   "metadata": {},
   "source": [
    "# Setup and Load Data üìÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be67a4-d44c-4670-888c-3285a85d90d8",
   "metadata": {},
   "source": [
    "## Import Libraries üìö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e34753-0d19-459c-9050-645c67aadf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, MaxPool2D, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import cv2\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714ebf7e-6a87-4311-b55b-07038542ff94",
   "metadata": {},
   "source": [
    "## Setup üõ†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4ba0f-29e5-4bf4-970d-41351413d662",
   "metadata": {},
   "source": [
    "The dataset is small, and both ANN and CNN models can train quickly on a CPU. However, if you have a GPU, training will be faster, especially for CNN. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d871ec79-fd35-4614-9bb5-aa795bc5ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"CUDA support:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU details:\", tf.config.experimental.get_device_details(tf.config.list_physical_devices('GPU')[0]) if tf.config.list_physical_devices('GPU') else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acafe42-3a92-41f8-a0b2-74894b258a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM (Out Of Memory) errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9588c5-0f0f-4f7e-a923-8194718952ce",
   "metadata": {},
   "source": [
    "# Load data üì•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60931329-01ec-4c04-a43d-6042b73f5436",
   "metadata": {},
   "source": [
    "üí°Download the dataset from Kaggle https://www.kaggle.com/competitions/digit-recognizer/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ebc55-0698-41a5-9770-ac4eac9989f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset path\n",
    "dataset_path = \"datasets/digit_recognizer\"\n",
    "\n",
    "# Read CSV File\n",
    "train = pd.read_csv(os.path.join(dataset_path, \"train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6c8bcc-5ac0-4487-a8d1-bdd74f7e3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a8c66-36b3-46fc-81b6-ef1eb7f6863b",
   "metadata": {},
   "source": [
    "## Extract Features and Label üóÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852e5fa-541e-4999-b1cb-925c7de3f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From train dataset\n",
    "y_train = train[\"label\"]\n",
    "X_train = train.drop(labels=[\"label\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd40c7-901a-4950-aa50-ac3de97f9345",
   "metadata": {},
   "source": [
    "# EDA üîç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18bb11-15a9-4f2d-bf0b-d613ed373bb8",
   "metadata": {},
   "source": [
    "## Class Distribution üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb72ae-6934-4ba3-b7a8-9cfb73822d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count class distribution\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=list(class_distribution.keys()), y=list(class_distribution.values()))\n",
    "plt.xlabel(\"Class Labels\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36a40d-9e6b-4b3a-a660-ae410449b6d3",
   "metadata": {},
   "source": [
    "We have similar counts for the 10 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8f813-728f-4f35-b7ee-107956e4623b",
   "metadata": {},
   "source": [
    "## Number of images üñºÔ∏è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d189284-2e70-40d5-801b-d978e5dbd4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c0189-edd0-41ae-b456-7875e017643c",
   "metadata": {},
   "source": [
    "## Preview same samples üëÅÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941aeb7-fa82-401d-a45f-e1977b4fbce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i in range(6):  # Display only 6 images\n",
    "    plt.subplot(2, 3, i+1)  # 2 rows, 3 columns\n",
    "    plt.imshow(X_train.iloc[i].values.reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Label: {y_train.iloc[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178cb11b-22e7-48eb-a8c1-afebebc0051b",
   "metadata": {},
   "source": [
    "##  Check for Null and Missing Values üîç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb74416-9a79-4901-9c32-33f82a1896b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac51a41c-8b6d-4c88-956d-602ce699dae8",
   "metadata": {},
   "source": [
    "- count = 784: There are 784 columns (pixels in the 28x28 images).\n",
    "- unique = 1: There is only one unique value (either True or False).\n",
    "- top = False: The most common value is False, meaning no missing values were found.\n",
    "- freq = 784: All 784 columns have False, confirming that no missing values exist.\n",
    "\n",
    "Conclusion: There are no missing values in X_train or test. So we can safely go ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e5f78-79a8-4654-bb9c-8d586b3a249d",
   "metadata": {},
   "source": [
    "# Preprocess Data üì¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21571465-e678-4313-9eba-9c248efbac7d",
   "metadata": {},
   "source": [
    "## Normalization üìè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288d5c2-0b70-45c0-b3a6-dc930bc70ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a09d1-f1a5-4d43-8e54-ef9e37e06299",
   "metadata": {},
   "source": [
    "## Reshape To Match The Keras's Expectations üîÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc3880-c1a2-433d-9acb-4b41183e3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d59d67-183a-45be-af78-a024b73a64b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d102e6d-9352-4b40-90f1-b6ec4953fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067257ca-aa36-4379-a176-491651a812a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first image\n",
    "plt.imshow(X_train[0].squeeze(), cmap='gray')  # Remove the extra channel\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d659c-1bcf-44ff-96a0-cef961c2a387",
   "metadata": {},
   "source": [
    "## Split Data ‚úÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fd3c9-4455-41dd-89d6-62db83b854db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f01f2-7206-4906-b7e8-29ae7ca7ab95",
   "metadata": {},
   "source": [
    "A small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c9bc0a-e0f7-46f5-91aa-aca9b563d048",
   "metadata": {},
   "source": [
    "## Data Augmentation üé®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8cd07-f463-44b4-87f2-e59095649aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,  # Randomly rotate images\n",
    "    zoom_range=0.1,     # Randomly zoom image\n",
    "    width_shift_range=0.1,  # Randomly shift images horizontally\n",
    "    height_shift_range=0.1,  # Randomly shift images vertically\n",
    "    horizontal_flip=False,   # Randomly flip images\n",
    "    vertical_flip=False      # Randomly flip images\n",
    ")\n",
    "\n",
    "# Fit the generator to the training data\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2899bc-a956-4219-9c51-d4c4420268c6",
   "metadata": {},
   "source": [
    "Let's jump into **training our neural network** and see how it performs! üß†üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3cb230-3a6c-41b0-a415-27eab37a66ca",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e86b03-9391-4ace-a870-64bfff763b58",
   "metadata": {},
   "source": [
    "## Train the Model üèãÔ∏è‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb7095-3631-4f8b-9044-2f8589299f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1bc05-967a-4bc0-be0f-e41daa9955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    # Input layer\n",
    "    Input(shape=(28, 28, 1)),\n",
    "    # First convolutional block\n",
    "    Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu'),\n",
    "    Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Second convolutional block\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # Output layer\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', mode='max', patience=3, verbose=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d6ad0-91f3-42a0-9011-03edb112bee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=32, # Without Augmentation : val_accuracy = 98%\n",
    "#                     validation_data=(X_val, y_val),\n",
    "#                     callbacks=[early_stop, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be25e2-ef05-44c9-ab05-e0e73cdbb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),  # Use the ImageDataGenerator to augment data\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36550e-2b9c-4bb7-a3d8-3dbff16d31b1",
   "metadata": {},
   "source": [
    "## Evaluate the Model üî¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb064294-ccae-4b5e-8ae3-35979b6c6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "fix, ax = plt.subplots(2, 1)\n",
    "\n",
    "ax[0].plot(history.history['loss'], color='b', label='Training Loss')\n",
    "ax[0].plot(history.history['val_loss'], color='r', label='Validation Loss')\n",
    "ax[0].set_title(\"CNN Model\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label='Training accuracy')\n",
    "ax[1].plot(history.history['val_accuracy'], color='r', label='Validation accuracy')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee5225-058b-4d19-a88e-5c0b1868b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of images to display\n",
    "num_images = 9\n",
    "\n",
    "# Select random indices from X_test\n",
    "indices = np.random.choice(len(X_val), num_images, replace=False)\n",
    "images = X_val[indices]\n",
    "y_val = np.array(y_val)\n",
    "true_labels = y_val[indices]\n",
    "\n",
    "# Expand dimensions and predict\n",
    "predictions = [np.argmax(model.predict(np.expand_dims(img, axis=0))) for img in images]\n",
    "\n",
    "# Plot images with actual and predicted labels\n",
    "fig, axes = plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i], cmap=\"gray\")\n",
    "    ax.set_title(f\"True: {true_labels[i]}\\nPred: {predictions[i]}\", fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee2aad-f22b-4890-80d2-c3a98de2777b",
   "metadata": {},
   "source": [
    "# Confusion Matrix  üü†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de79516-e35d-40d2-8547-e7b5142baa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "y_pred_labels = [np.argmax(i) for i in y_pred]\n",
    "cm = tf.math.confusion_matrix(labels=y_val, predictions=y_pred_labels)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2fd2fa-fa0e-479f-bf12-6ade12b6bed4",
   "metadata": {},
   "source": [
    "Our CNN performs exceptionally well on all digits, with only a few errors given the validation set size of 4,200 images.  \n",
    "\n",
    "However, the model struggles slightly with the digit **4**, often misclassifying it as **9**. This is understandable, as distinguishing between 4 and 9 can be challenging, especially when the curves are smooth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac9d1d-326c-40f3-a1f8-492456c37e14",
   "metadata": {},
   "source": [
    "# Run Inference ‚ö°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b6564-4d66-4625-a98c-79892f5221e9",
   "metadata": {},
   "source": [
    "## Save and Load Model üì•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ca276-e56e-4c0a-8069-d7da8b1ed0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"digit_recognizer_model.keras\")\n",
    "digit_recognizer_model= load_model('digit_recognizer_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204cc31-afcb-44c2-bc22-1da4d4208da1",
   "metadata": {},
   "source": [
    "## Predict Labels for test.csv üì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195add3-767b-4d44-971a-39001155da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test dataset\n",
    "test = pd.read_csv(os.path.join(dataset_path, \"test.csv\"))\n",
    "\n",
    "# Get the length of the train dataset\n",
    "print(len(train)\n",
    "     )\n",
    "# Check if there are any missing values in the test dataset and describe the result\n",
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127c57b-9c1a-493a-b582-a04e35247b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure test data is properly shaped and normalized\n",
    "test = test.values.reshape(-1, 28, 28, 1) / 255.0  # Normalize like X_train\n",
    "\n",
    "# Predict labels\n",
    "predictions = digit_recognizer_model.predict(test)\n",
    "\n",
    "# Convert predictions to label indices (0-9)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\"ImageId\": np.arange(1, len(predicted_labels) + 1),\n",
    "                           \"Label\": predicted_labels})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv(\"submission_v1.csv\", index=False)\n",
    "\n",
    "print(\"Submission file saved as submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab1c20-8cf7-4a51-b805-b62c5ddcbd85",
   "metadata": {},
   "source": [
    "Submit your file on https://www.kaggle.com/competitions/digit-recognizer/submissions to see the score!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
